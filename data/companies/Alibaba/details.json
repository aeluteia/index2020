{"id":"Alibaba","printName":"Alibaba Group Holding Limited","basicInformation":"<p>Headquartered in China, Alibaba runs China&#x2019;s largest e-commerce platform, alongside other internet services, ranging from cloud computing and office tools to video streaming and food delivery platforms. It has an annual active base of <a href=\"https://doc.irasia.com/listco/hk/alibabagroup/annual/2020/ar2020.pdf\">780 million users</a> in China.</p>","keyTakeawaysTitle":"Key takeaways","keyTakeaways":"<ul>\n  <li>Apple earned the highest privacy score of any digital platform we evaluated, and stood out for strong disclosure of its security policies. </li>\n</ul><ul>\n  <li>Apple lacked transparency about its process for removing apps from the App Store for violations to iOS rules.</li>\n</ul><ul>\n  <li>Apple lagged behind its peers on human rights due diligence, but strengthened its human rights commitments.</li>\n</ul>","keyFindingsTitle":"Key findings","keyFindings":"<p><span class=\"font-bold\">New to the 2020 RDR Index, Alibaba was one of the lowest scoring digital platforms in our ranking. It was the only company that did not explicitly commit to respect users&apos; privacy rights, though it did state that it &#x201C;puts the user first&#x201D; when it comes to data protection.</span> In 2020, in response to the COVID-19 pandemic, the Chinese government rolled out an algorithmically driven <a href=\"https://www.nytimes.com/2020/03/01/business/china-coronavirus-surveillance.html\">health tracking system</a> as a way to monitor citizens and control the spread of the disease, leveraging technologies built by both Alibaba and Tencent [LINK TO TENCENT CARD] and triggering public concerns around privacy rights. Like other Chinese internet companies, Alibaba does not maintain adequate transparency about its processes for handling government requests for content restrictions or user information, due primarily to China&#x2019;s tight controls over the internet and a series of laws and regulations affecting privacy and expression. Also in 2020, former U.S. Secretary of State Mike Pompeo <a href=\"https://www.bbc.com/news/business-53844725?intlink_from_url%3Dhttps://www.bbc.com/news/world%26\">called on U.S. tech companies</a> to cut ties with their Chinese peers, including Alibaba. In response, Alibaba&#x2019;s chief executive Daniel Zhang <a href=\"https://www.bbc.com/news/business-53844725?intlink_from_url%3Dhttps://www.bbc.com/news/world%26\">emphasized</a> the importance of the e-commerce platform for American brands, retailers, and small businesses. <a href=\"https://www.nytimes.com/2020/12/23/business/alibaba-antitrust-jack-ma.html\">The antitrust campaign</a> launched by Chinese government against China&#x2019;s Internet companies recently including Alibaba may stifle its growth but push it to act more transparently in the future.</p>","changesTitle":"Changes since 2019","changes":"<ul>\n  <li>Apple published a commitment recognizing freedom of expression and information as a human right (G1).</li>\n</ul><ul>\n  <li>Apple began reporting the number of app removal demands it receives from governments (F6) and publishing some information about its process for responding to private requests for user information (P10b).</li>\n</ul>","keyRecommendationTitle":"Key recommendations","keyRecommendation":"<ul>\n  <li>Be transparent about rules enforcement. Apple should publish data about actions it takes to enforce its own rules, including about apps removed from its App Store, and strengthen mechanisms to appeal enforcement decisions. </li>\n</ul><ul>\n  <li>Strengthen human rights due diligence. Apple should commit to conducting robust, systematic risk assessments on all aspects of its operations and business practices. The scope of these assessments should include evaluting risks to freedom of expression and information and the right to non-discrimination associated with the development and use of algorithmic systems and of its targeted advertising policies and practices. </li>\n</ul><ul>\n  <li>Increase user control. Apple should give users more options to control their own information. Targeted advertising should be <span class=\"italic\">off </span>by default. </li>\n</ul>","governance":"<p>Apple ranked fifth among digital platform companies we evaluated, falling short on human rights due diligence in comparison to its U.S. peers. </p><ul>\n  <li><span class=\"font-bold\">Commitment to human rights: </span>Apple disclosed a clear and explicit commitment to protect and respect privacy and freedom of expression and information but failed to disclose a similar human rights commitment in its use and development of algorithmic systems (G1).</li>\n</ul><ul>\n  <li><span class=\"font-bold\">Human rights due diligence: </span>Apple disclosed it conducts limited assessments of privacy risks associated with government regulations in the markets in which it operates (G4a), but does not provide evidence of conducting due diligence in other areas, including of its own policy enforcement, on its development and use of algorithmic systems, or on targeted advertising.</li>\n</ul><ul>\n  <li><span class=\"font-bold\">Stakeholder engagement: </span>Apple failed to provide evidence of systematic engagement with stakeholders whose privacy and freedom of expression and information are directly impacted by the company (G5).</li>\n</ul><ul>\n  <li><span class=\"font-bold\">Remedy: </span>Apple disclosed little about its remedy mechanisms to address users&#x2019; freedom of expression and information as well as privacy grievances (G6a) and even less about its processes for users and developers to appeal app removals from the App Store (G6b).</li>\n</ul>","freedom":"<p>Apple lagged behind South Korea-based Kakao and most of its U.S. peers in this category. </p><ul>\n  <li><span class=\"font-bold\">Content moderation: </span>Apple did not clearly disclose platform rules and its process for enforcing them (F3a), including rules on bots (F13). Nor did it report any data about content removals and account suspensions for violations to these policies (F4a, F4b). It offered almost no information on whether or how it notifies users when content is removed (F8).</li>\n</ul><ul>\n  <li><span class=\"font-bold\">Algorithmic use and content curation: </span>Apple revealed nothing about how it uses algorithms to curate, rank, or recommend content in its App Store (F12).</li>\n</ul><ul>\n  <li><span class=\"font-bold\">Advertising content and targeting: </span>The company lacked transparency about its ad content and ad targeting rules and enforcement process (F3b, F3c), and it did not publish data on content removed for violating these rules (F4c).</li>\n</ul><ul>\n  <li><span class=\"font-bold\">Censorship demands:</span> Apple was transparent about its process for responding to government censorship demands (F5a) but disclosed very little about censorship requests submitted through private processes (F5b). For the first time, it reported the number of government takedown requests for apps in its App Store, and it listed associated subject matters, following through on a prior commitment to do so. It also began disclosing the number of App Store takedown requests from governments for alleged violations of Apple&apos;s own Terms of Service (F6), but none about private requests (F7).</li>\n</ul>","privacy":"<p>Apple earned the highest privacy score, but fell short in key areas.</p><ul>\n  <li><span class=\"font-bold\">Handling of user data: </span>While Apple did disclose some information about what user data it collects and shares, and why, it did not disclose anything about its data inference policies (P3b). Apple remained the only platform in the RDR Index to disclose it does not track users around the web, but the company disclosed nothing about whether it collects information about users through third-party data brokers (P9). </li>\n</ul><ul>\n  <li><span class=\"font-bold\">Government and private demands for user data: </span>Apple was transparent about its process for responding to government demands for user information (P10a), but disclosed less information about user information requests submitted through private processes (P10b). It provided data about government demands (P11a), but like its U.S. peers, Facebook did not divulge the exact number of requests received for user data under the Foreign Intelligence Surveillance Act or National Security Letters, or the actions it took in response to these requests, since it is <a href=\"http://www.congress.gov/bill/114th-congress/house-bill/2048\">prohibited by law</a> from doing so. It also committed to notify users when government entities demand access to their information (P12). It did not publish any data about private requests (P11b), nor did it commit to notify users when their information is requested through private processes (P12).</li>\n</ul><ul>\n  <li><span class=\"font-bold\">Security:</span> Apple disclosed more about its security policies than any other digital platform we evaluated. It was fully transparent about its internal processes for keeping user information secure (P13) and offered resources and tools to help users protect their security (P17, P18). It was less clear about its policies on data breaches (P15), and it disclosed limited information about how it addresses security vulnerabilities (P14).</li>\n</ul>"}